{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.9.0 64-bit ('.venv': venv)",
   "display_name": "Python 3.9.0 64-bit ('.venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bb3a6e0f195b97819cc1ba12690aa5fdd302d01770eabe5b51524d65babf4002"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Doing Text Analysis with Azure Cognitive Services Text Analytics\n",
    "\n",
    "## Overview\n",
    "This notebook goes through the basics of writing a custom Cognitive Services Text Analytics application for analyzing long, open-form text. \n",
    "Specifically, we'll get key phrases and common entities (e.g. organizations) from each text input. \n",
    "\n",
    "Documentation for how to use Cognitive Services Text Analytics with Python can be found [here (SDK V3)](https://docs.microsoft.com/en-us/python/api/azure-ai-textanalytics/azure.ai.textanalytics.textanalyticsclient?view=azure-python).\n",
    "\n",
    "### How to use this notebook\n",
    "This notebook contains all instructions and code needed to run text analytics on multiple text files. **For the code to function properly, you'll need to add two things in an untracked file:**\n",
    "\n",
    "1. Cognitive Services key, and\n",
    "2. Cognitive services endpoint.\n",
    "\n",
    "Remember to treat these Azure credentials like passwords: keep them private and secure!\n",
    "\n",
    "**There are two ways to run the notebook code:**\n",
    "\n",
    "1. Go through each section and click the green arrow <span style=\"color:green\">&#9655</span> on the top, left-hand side of each code block; or\n",
    "2. Run all cells by clicking the double-arrow icon at the very top of the notebook.\n",
    " \n",
    "\n",
    "### Let's get started!\n",
    "Read through the section below to learn more about Cognitive Services Text Analytics. Then run the code block below to import and process the sample text files stored in the *TextFiles* folder.\n",
    "\n",
    "To process your own text, replace the sample text files in the *TextFiles* folder with your own .txt files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## More information on Text Data\n",
    "This notebook takes a set of text stored in the same folder. These input text files can be different lengths, but distinct sentences or paragraphs should be separated by a new line.\n",
    "\n",
    "You may run this notebook on the sample text provided, which include text copied from Wikipedia articles. Each text file contains content from a single Wikipedia article, with the file name indicating the name of the article.\n",
    "\n",
    "Alternatively, you may upload your own text files into the **TextFiles** folder. How you organize the text into different files will depend on your particular needs. Here is an example scenario for handling open-form survey responses:\n",
    "\n",
    "1. Copy and paste all responses to a single question into a unique text file. \n",
    "    * Copying and pasting from Excel rows works great, as it will include a newline between each unique response.\n",
    "2. Save each text file in a subfolder called \"TextFiles\" (or update the filepath in the code block below where it says \"To Do\").\n",
    "\n",
    "**Troubleshooting**\n",
    "\n",
    "If you run into any issues as you run the code blocks, here are some troubleshooting tips that might be helpful:\n",
    "* The Cognitive Services Text Analytics Python SDK V3 requires the following input formats:\n",
    "    * Raw Text Input\n",
    "    * Encoding: UTF-8 or UTF-16\n",
    "    * Document size less than 5,120 characters (this is handled in the import data section)\n",
    "    * Some methods (e.g. entity recognition) require a batch size of 5 or less.\n",
    "    * Input text should be in one of the following formats:\n",
    "        * a list of strings: \n",
    "        \n",
    "            ```list[str]```\n",
    "        * a list of text documents: \n",
    "        \n",
    "            ```list[TextDocumentInput]```\n",
    "        * or a list of dictionary representations with at least two string elements, ID and text:\n",
    "\n",
    "             ```list[dict[str, str]]``` \n",
    "             \n",
    "             E.g. ```texts = [{'id': Unique_Id1, 'text': Input_Text1}, {'id': Unique_ID2, 'text': Input_Text2}, ...]```\n",
    "    * If you wish to specify the ID and language on a per-item basis you must use as input a list of text documents or a list of dict representations. \n",
    "    * [More info on data limits here](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview#data-limits)\n",
    "* An \"HttpOperationErrText\", \"HttpResponseError\" or similar error indicates that the Text Analytics method did not get a correctly formatted input. Some things to check:\n",
    "    * Batch size limits.\n",
    "    * Iterating through multiple text files such that the method inputs fit one of the three options above.\n",
    "    * Any list of dictionary inputs contains unique ids for each dictionary. \n",
    "* A \"list index out of range\" error indicates that the input text is too long for the Text Analytics client to handle.\n",
    "* Run into other issues? Please let us know by opening an issue on the [GitHub repo](https://github.com/jenfoxbot/text-analytics-walkthrough)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.0\nWikipedia-A-History-of-the-Birds-of-Europe.txt.1\nWikipedia-Hypatia.txt.0\nWikipedia-Hypatia.txt.1\nWikipedia-Hypatia.txt.2\nWikipedia-Indigeneous-Peoples-of-the-Americas.txt.0\nWikipedia-Indigeneous-Peoples-of-the-Americas.txt.1\nWikipedia-Indigeneous-Peoples-of-the-Americas.txt.2\n"
     ]
    }
   ],
   "source": [
    "# This code imports text files stored in 'TextFiles' folder and splits them \n",
    "# into dictionaries of fewer than 5,100 characters at the last new line.\n",
    "# The final dictionary names are printed to the screen.\n",
    "\n",
    "import os\n",
    "# Note: your text files may have a different encoding than the one below\n",
    "enc = 'utf-8'\n",
    "\n",
    "# Import the text files in the TextFiles folder\n",
    "# TO DO: Update file path as necessary\n",
    "text_folder = os.path.join('TextFiles')\n",
    "\n",
    "# Create a collection of texts with id (file name) and text (contents) properties\n",
    "texts = []\n",
    "for file_name in os.listdir(text_folder):\n",
    "    survey_text = open(os.path.join(text_folder, file_name), encoding=enc).read()\n",
    "    \n",
    "    # Counter to track number of times split is done \n",
    "    text_split_counter = 0\n",
    "    survey_text_list = []\n",
    "\n",
    "    if len(survey_text) > 5100:\n",
    "        while len(survey_text) > 5100:\n",
    "            for char in (0,5100):\n",
    "                # Get the first 5100 characters\n",
    "                text_holder = survey_text[0:5100]\n",
    "                # Go back to the last new line and save in a list. Save index of split\n",
    "                for item in range(len(text_holder[::-1])):\n",
    "                    #print(text_holder[item])\n",
    "                    if text_holder[item] == \"\\n\":\n",
    "                        # Store index of last newline\n",
    "                        index = item\n",
    "                        # Save list up to the last newline\n",
    "                        split_text = text_holder[0:index]\n",
    "            #Save split text\n",
    "            text = {\"id\": f\"{file_name}.{text_split_counter}\", \"text\": split_text}\n",
    "            texts.append(text)\n",
    "            # Update counter\n",
    "            text_split_counter += 1\n",
    "            # Remove split text from survey_text \n",
    "            survey_text = survey_text[index:len(survey_text)]\n",
    "        # Save split text and update text list        \n",
    "        text = {\"id\": f\"{file_name}.{text_split_counter}\", \"text\": survey_text}\n",
    "        texts.append(text)\n",
    "    \n",
    "    else:\n",
    "        text = {\"id\": file_name, \"text\": survey_text}\n",
    "        texts.append(text)\n",
    "\n",
    "for text_num in range(len(texts)):\n",
    "    # print the open-form text\n",
    "    print(texts[text_num]['id'])\n",
    "    # OPTIONAL: To see all text, uncomment the following 2 lines\n",
    "    #for i in range(number_of_lines):\n",
    "        #print('{}\\n{}\\n'.format(texts[text_num]['id'], texts[text_num]['text']))  "
   ]
  },
  {
   "source": [
    "## Get the Key and Endpoint for your Cognitive Services resource\n",
    "This notebook assumes you already have a Cognitive Services resource in your Azure subscription. (If not, follow the instructions in **Step 3** the [Read Me of this github repo](https://github.com/microsoft/text-analytics-walkthrough).)\n",
    "\n",
    "To use Azure Cognitive Services, you'll need a key, similar to password, and an endpoint, which accesses the Cognitive Services resource you created. It's important to keep both of these private and secure! \n",
    "\n",
    "### A. Create a private file to store your Azure key and endpoint.\n",
    "The code block below installs a Python library called *dotenv*, which allows you to read environment variables from a file. You can store your Azure key and endpoint in this (untracked) file, so if you fork this project your Azure credentials  remain private.\n",
    "\n",
    "Run the code below to install the library and create the *.env* file where you'll store your key and endpoint.\n",
    "\n",
    "*Note: If you're on a Linux or Unix machine, use the appropriate command line calls.*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (0.15.0)\n",
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# WINDOWS: Use the following commands\n",
    "!pip install python-dotenv\n",
    "\n",
    "!echo YOUR_COG_KEY= > .env\n",
    "!echo YOUR_COG_ENDPOINT= >> .env\n",
    "\n"
   ]
  },
  {
   "source": [
    "### B. Get your Azure key and endpoint and store them in the *.env* file.\n",
    "\n",
    "1. In VS Code, open the *.env* file you just created. You should see two (blank) variables: *YOUR_COG_KEY* and *YOUR_COG_ENDPOINT*. \n",
    "1. In a browser window, open the [Azure portal](https://portal.azure.com).\n",
    "2. Select your cognitive services resource. On the **Overview** page, click on **\"Keys and endpoint\"** in the menu on the left-hand side (under Resource Management).\n",
    "1. Copy the **Key1** for your resource and paste it into the *.env* file for **YOUR_COG_KEY** after the equals sign and **between quotes**, without any spacing, like so:\n",
    "    ```YOUR_COG_KEY='COG_KEY_HERE'```\n",
    "2. Copy the **endpoint** for your resource and and paste into the *.env* file for **YOUR_COG_ENDPOINT**:\n",
    "    ```YOUR_COG_ENDPOINT='COG_ENDPOINT_HERE'```\n",
    "3. Run the code in the cell to load the variables from the *.env* file into this notebook environment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "source": [
    "# Import dotenv library functions and load in Azure credentials from .env file, \n",
    "# then print resulting variables to check for accuracy.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')\n",
    "os.getenv(\"CONNECTION_STRING\")\n",
    "\n",
    "cog_key = os.getenv('YOUR_COG_KEY')\n",
    "cog_endpoint = os.getenv('YOUR_COG_ENDPOINT')\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "source": [
    "## Install Azure Cognitive Services Text Analytics SDK\n",
    "Run the code below to install the text analytics SDK onto your local environment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: azure-ai-textanalytics in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (5.1.0b2)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from azure-ai-textanalytics) (1.1.25)\n",
      "Requirement already satisfied: six>=1.6 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from azure-ai-textanalytics) (1.15.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.4.0 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from azure-ai-textanalytics) (1.8.2)\n",
      "Requirement already satisfied: msrest>=0.6.0 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from azure-ai-textanalytics) (0.6.19)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (1.3.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from msrest>=0.6.0->azure-ai-textanalytics) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.4.0->azure-ai-textanalytics) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.0->azure-ai-textanalytics) (3.1.0)\n",
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\admin\\onedrive - microsoft\\git\\text-analytics-walkthrough\\.venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-textanalytics --pre"
   ]
  },
  {
   "source": [
    "## Import Cognitive Services libraries and create a Text Analytics client\n",
    "\n",
    "Run the following code to import the Cognitive Services Text Analytics library. We'll also create a client for the text analytics cognitive services resource, which takes in two inputs: your key and endpoint that we set above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(cog_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=cog_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Get a client for your text analytics cognitive service resource\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
    "                                            credentials=CognitiveServicesCredentials(cog_key))"
   ]
  },
  {
   "source": [
    "## Extract Key Phrases\n",
    "We're now ready to start using the text analytics service! First, let's get a list of key phrases from our set of texts. This helps give some indication of common themes and talking points without us having to read all of the text.\n",
    "\n",
    "When you run the code block below, it outputs key phrases for each set of texts. \n",
    "It also prints the file name, basic statistics for each text file (e.g. character count), and the number of key phrases.\n",
    "\n",
    "### More Info\n",
    "* The key phrases service processes each input as-a-whole. This means that key phrases are extracted based on the entire input text.\n",
    "* The number of returned key phrases is proportional to the size of the input text.\n",
    "* The SDK documentation for this service can be found [here](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-language-textanalytics/azure.cognitiveservices.language.textanalytics.textanalyticsclient?view=azure-python#key-phrases-show-stats-none--documents-none--custom-headers-none--raw-false----operation-config-)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.0\n",
      "\n",
      "Statistics: {'character_count': 4171, 'transaction_count': 5}\n",
      "\n",
      "Number of Key Phrases: 107\n",
      "\t John Gould's five-volume Birds of Europe\n",
      "\t then-known birds\n",
      "\t bird species\n",
      "\t Ornithology of Francis Willughby of Middleton\n",
      "\t Dresser's extensive collection of birds\n",
      "\t John Wilkins\n",
      "\t Books of Ornithology\n",
      "\t modern ornithology\n",
      "\t early works\n",
      "\t pioneering ornithological work of John Ray\n",
      "\t anatomical features\n",
      "\t Francis Bacon\n",
      "\t classification of specimens\n",
      "\t quarto parts\n",
      "\t Early ornithologies\n",
      "\t effective classification system\n",
      "\t innovative features\n",
      "\t dichotomous key\n",
      "\t century\n",
      "\t English-language ornithologies\n",
      "\t cost\n",
      "\t English Royal Society\n",
      "\t History\n",
      "\t readers\n",
      "\t Dutch artist John Gerrard Keulemans\n",
      "\t Richard Bowdler Sharpe\n",
      "\t worldwide distribution\n",
      "\t advancement of knowledge\n",
      "\t earlier volumes\n",
      "\t first-hand knowledge\n",
      "\t modern zoology\n",
      "\t volume ornithological book\n",
      "\t Dresser's outdated views\n",
      "\t Zoological Society of London\n",
      "\t Henry Eeles Dresser\n",
      "\t Mathurin Jacques Brisson\n",
      "\t Georges Cuvier\n",
      "\t similar fauna\n",
      "\t Gessner's Historia animalium\n",
      "\t Middle East\n",
      "\t overall size\n",
      "\t adjacent geographical areas\n",
      "\t bird's beak\n",
      "\t members\n",
      "\t René Réamur\n",
      "\t Carl Linnaeus\n",
      "\t alphabetical order\n",
      "\t arbitrary criteria\n",
      "\t Atlantic archipelagos of Madeira\n",
      "\t Ulisse Aldrovandi\n",
      "\t writers\n",
      "\t Conrad Gessner\n",
      "\t strands\n",
      "\t variations\n",
      "\t appearance\n",
      "\t long run\n",
      "\t eggs\n",
      "\t Ornithologiae Libri Tres\n",
      "\t Latin\n",
      "\t North Africa\n",
      "\t Canary Islands\n",
      "\t German naturalist Erwin Stresemann\n",
      "\t Pierre Belon\n",
      "\t behaviour\n",
      "\t ecology\n",
      "\t feet\n",
      "\t commentator\n",
      "\t literature\n",
      "\t limited influence\n",
      "\t librarian\n",
      "\t Western Palearctic Region\n",
      "\t proverbs\n",
      "\t references\n",
      "\t authority of Aristotle\n",
      "\t migratory movements\n",
      "\t field observers\n",
      "\t empirical method\n",
      "\t teachings\n",
      "\t rift\n",
      "\t pages of text\n",
      "\t use\n",
      "\t observation\n",
      "\t experiment\n",
      "\t encyclopaedia\n",
      "\t commercial success\n",
      "\t centuries\n",
      "\t authors\n",
      "\t arrangement\n",
      "\t study\n",
      "\t tradition\n",
      "\t plates of illustrations\n",
      "\t contemporary reviewers\n",
      "\t network of contacts\n",
      "\t group\n",
      "\t emblem\n",
      "\t content\n",
      "\t church\n",
      "\t practice\n",
      "\t Azores\n",
      "\t extraneous material\n",
      "\t asterisk\n",
      "\t resources\n",
      "\t task\n",
      "\t information\n",
      "\t copies\n",
      "\t subscriber\n",
      "\t Background\n",
      "\n",
      "\n",
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.1\n",
      "\n",
      "Statistics: {'character_count': 1215, 'transaction_count': 2}\n",
      "\n",
      "Number of Key Phrases: 34\n",
      "\t species\n",
      "\t Gould's work\n",
      "\t John Gould's five-volume Birds of Europe\n",
      "\t extensive collection of European birds\n",
      "\t European languages\n",
      "\t amateur ornithologist Henry Eeles Dresser\n",
      "\t librarian\n",
      "\t Middle East\n",
      "\t North Africa\n",
      "\t Atlantic archipelagos of Madeira\n",
      "\t parts\n",
      "\t geographical range\n",
      "\t businessman\n",
      "\t eggs\n",
      "\t number of ornithologies\n",
      "\t Canary Islands\n",
      "\t area\n",
      "\t texts\n",
      "\t movements\n",
      "\t early nineteenth century\n",
      "\t Zoological Society of London\n",
      "\t worldwide distribution\n",
      "\t Western Palaearctic realm\n",
      "\t Richard Bowdler Sharpe\n",
      "\t variation\n",
      "\t Azores\n",
      "\t English\n",
      "\t linguistic skills\n",
      "\t books\n",
      "\t network of contacts\n",
      "\t resources\n",
      "\t task\n",
      "\t great encyclopaedia\n",
      "\t new specimens\n",
      "\n",
      "\n",
      "Wikipedia-Hypatia.txt.0\n",
      "\n",
      "Statistics: {'character_count': 4275, 'transaction_count': 5}\n",
      "\n",
      "Number of Key Phrases: 99\n",
      "\t Library of Alexandria\n",
      "\t bishop of Alexandria\n",
      "\t mathematician Theon of Alexandria\n",
      "\t novel Hypatia\n",
      "\t Roman prefect of Alexandria\n",
      "\t Hypatia's father Theon of Alexandria\n",
      "\t Theon's school\n",
      "\t Eastern Roman Empire\n",
      "\t legend of Saint Catherine of Alexandria\n",
      "\t great mathematician\n",
      "\t Theon's edition of Euclid's Elements\n",
      "\t father Theon's commentary\n",
      "\t Hypatia's lifetime\n",
      "\t School\tNeoplatonism\n",
      "\t Province of Egypt\n",
      "\t new edition of Euclid's Elements\n",
      "\t existing text of Euclid's Elements\n",
      "\t Neoplatonic school\n",
      "\t Hypatia's death\n",
      "\t female mathematician\n",
      "\t Hypatia's murder\n",
      "\t century manuscript\n",
      "\t Era\tAncient philosophy\n",
      "\t Orestes\n",
      "\t Cyril\n",
      "\t great teacher\n",
      "\t great influence\n",
      "\t Theon's mathematical work\n",
      "\t Diophantus's original text\n",
      "\t mob of Christians\n",
      "\t symbol of opposition\n",
      "\t modern scholars\n",
      "\t Region\tWestern philosophy\n",
      "\t Hellenistic Mouseion\n",
      "\t surviving text of Ptolemy's Almagest\n",
      "\t future bishop of Ptolemais\n",
      "\t symbol of Christian virtue\n",
      "\t political feud\n",
      "\t political elite\n",
      "\t Christian students\n",
      "\t modern standards\n",
      "\t Ancient sources\n",
      "\t Plotinian Neoplatonism\n",
      "\t leading future Neoplatonists\n",
      "\t Hellenistic Neoplatonist philosopher\n",
      "\t Main interests Mathematics Astronomy\n",
      "\t Charles Kingsley's\n",
      "\t Apollonius of Perga's treatise\n",
      "\t precursor\n",
      "\t Watts\n",
      "\t Synesius\n",
      "\t production\n",
      "\t icon\n",
      "\t title\n",
      "\t women's rights\n",
      "\t European literature\n",
      "\t conic sections\n",
      "\t Damascius\n",
      "\t classical historian Edward\n",
      "\t astronomer\n",
      "\t portrayals\n",
      "\t midst\n",
      "\t destruction\n",
      "\t daughter\n",
      "\t prominent thinker\n",
      "\t historical fact\n",
      "\t pride\n",
      "\t basis\n",
      "\t accusing\n",
      "\t lector\n",
      "\t wise counselor\n",
      "\t reconciling\n",
      "\t volume Arithmetica\n",
      "\t constructed astrolabes\n",
      "\t martyr\n",
      "\t head\n",
      "\t pagans\n",
      "\t feminist movement\n",
      "\t primary achievement\n",
      "\t teachings of Iamblichus\n",
      "\t course\n",
      "\t Wikipedia\n",
      "\t free encyclopedia\n",
      "\t years of copying\n",
      "\t hydrometers\n",
      "\t Christianity\n",
      "\t membership\n",
      "\t Rumors\n",
      "\t Peter\n",
      "\t textbook\n",
      "\t centuries\n",
      "\t emulation\n",
      "\t Catholicism\n",
      "\t Middle Ages\n",
      "\t Age of Enlightenment\n",
      "\t scribal errors\n",
      "\t Hellenes\n",
      "\t Upbringing\n",
      "\t editions\n",
      "\n",
      "\n",
      "Wikipedia-Hypatia.txt.1\n",
      "\n",
      "Statistics: {'character_count': 4500, 'transaction_count': 5}\n",
      "\n",
      "Number of Key Phrases: 106\n",
      "\t description of Hypatia\n",
      "\t contemporary of Hypatia\n",
      "\t Hypatia taught students\n",
      "\t extant letters\n",
      "\t time\n",
      "\t teachings of Plotinus\n",
      "\t father Theon\n",
      "\t extant sources\n",
      "\t teachings of Iamblichus\n",
      "\t original Neoplatonism\n",
      "\t philosopher Theon\n",
      "\t Synesius of Cyrene\n",
      "\t Hypatia's mother\n",
      "\t Hypatia's brother\n",
      "\t Greek word Theon\n",
      "\t Hypatia's exact year of birth\n",
      "\t main varieties of Neoplatonism\n",
      "\t Neoplatonist historian Damascius\n",
      "\t pagan religious Neoplatonism\n",
      "\t account\n",
      "\t philosophers\n",
      "\t legacy of Hypatia's opinions\n",
      "\t theories\n",
      "\t principles of philosophy\n",
      "\t school of Plato\n",
      "\t mysteries of philosophy\n",
      "\t known students\n",
      "\t Career\n",
      "\t main sources of information\n",
      "\t Original Greek text\n",
      "\t philosophical capital\n",
      "\t Damascius's description\n",
      "\t Christian historian Socrates of Constantinople\n",
      "\t birth date\n",
      "\t Alexandrian school\n",
      "\t reign of Arcadius\n",
      "\t Richard Hoche\n",
      "\t polemical variety\n",
      "\t writings of Plato\n",
      "\t assembly of men\n",
      "\t dear son\n",
      "\t philosophical state of apatheia\n",
      "\t century Byzantine encyclopedia\n",
      "\t midpoint of Arcadius's reign\n",
      "\t impromptu public lectures\n",
      "\t complete liberation\n",
      "\t Synesius's\n",
      "\t lost work Life of Isidore\n",
      "\t Ptolemy's Almagest\n",
      "\t daughter\n",
      "\t Greco-Roman world\n",
      "\t emotions\n",
      "\t attainments\n",
      "\t commentary\n",
      "\t Book\n",
      "\t kind of cloak\n",
      "\t debate\n",
      "\t extraordinary dignity\n",
      "\t years\n",
      "\t consequence\n",
      "\t strong feelings of paternal connection\n",
      "\t wording\n",
      "\t chronicler John Malalas\n",
      "\t individual\n",
      "\t Epiphanius\n",
      "\t affections\n",
      "\t ease of manner\n",
      "\t self-possession\n",
      "\t Suda\n",
      "\t reputation\n",
      "\t physical beauty\n",
      "\t virtue\n",
      "\t prominent pupils\n",
      "\t tribon\n",
      "\t Serapeum\n",
      "\t Watts\n",
      "\t teknon\n",
      "\t pursuit\n",
      "\t person\n",
      "\t friend Herculianus\n",
      "\t woman\n",
      "\t bishop of Ptolemais\n",
      "\t eastern Libya\n",
      "\t Robert Penella\n",
      "\t printed edition\n",
      "\t cultivation\n",
      "\t mind\n",
      "\t literature\n",
      "\t science\n",
      "\t suggested dates\n",
      "\t biological sense\n",
      "\t presence\n",
      "\t magistrates\n",
      "\t Aristotle\n",
      "\t tolerant of Christians\n",
      "\t scholars\n",
      "\t Athens\n",
      "\t auditors\n",
      "\t death\n",
      "\t Mediterranean\n",
      "\t Ecclesiastical History\n",
      "\t distance\n",
      "\t instructions\n",
      "\t entry\n",
      "\t fact\n",
      "\t contrast\n",
      "\n",
      "\n",
      "Wikipedia-Hypatia.txt.2\n",
      "\n",
      "Statistics: {'character_count': 1043, 'transaction_count': 2}\n",
      "\n",
      "Number of Key Phrases: 22\n",
      "\t Damascius states\n",
      "\t contemporary of Hypatia\n",
      "\t father\n",
      "\t young man\n",
      "\t lexicographer Hesychius of Alexandria records\n",
      "\t fair of form\n",
      "\t lifelong virgin\n",
      "\t Christian historian\n",
      "\t bloody menstrual rags\n",
      "\t sooth\n",
      "\t lust\n",
      "\t lyre\n",
      "\t Philostorgius\n",
      "\t mathematics\n",
      "\t physical appearance\n",
      "\t ancient depictions\n",
      "\t lectures\n",
      "\t beauty\n",
      "\t sake\n",
      "\t talented astronomer\n",
      "\t desires\n",
      "\t pursuit\n",
      "\n",
      "\n",
      "Wikipedia-Indigeneous-Peoples-of-the-Americas.txt.0\n",
      "\n",
      "Statistics: {'character_count': 4221, 'transaction_count': 5}\n",
      "\n",
      "Number of Key Phrases: 132\n",
      "\t distinct indigenous peoples\n",
      "\t Indigenous Canadians\n",
      "\t indigenous peoplehood\n",
      "\t flora indigenous\n",
      "\t indigenous inhabitants\n",
      "\t Indigenous Americans\n",
      "\t myriad groups of indigenous peoples\n",
      "\t aboriginal peoples\n",
      "\t Americas\n",
      "\t Yupik peoples\n",
      "\t uncontacted peoples\n",
      "\t different indigenous languages\n",
      "\t aspects of indigenous cultural practices\n",
      "\t pre-Columbian peoples of North\n",
      "\t term Amerindian\n",
      "\t blanket term\n",
      "\t Arctic regions\n",
      "\t Arctic Inuit\n",
      "\t East Indies\n",
      "\t American Indian-European mixed race mestizos\n",
      "\t Métis people of Canada\n",
      "\t Nations-European mixed race\n",
      "\t European-derived Hispanic\n",
      "\t Hispanic America\n",
      "\t cultural commonalities\n",
      "\t cultural unity\n",
      "\t religion\n",
      "\t Aboriginal Canadians\n",
      "\t Mayan languages\n",
      "\t Quechuan languages\n",
      "\t recent times\n",
      "\t agriculture\n",
      "\t West Indies\n",
      "\t minority population of Métis people\n",
      "\t Asiatic Arctic Russian\n",
      "\t recent wave of migration\n",
      "\t monumental architecture\n",
      "\t Latin-American countries\n",
      "\t South America\n",
      "\t larger population\n",
      "\t subsistence practices\n",
      "\t Brazilian peoplehood\n",
      "\t cultures specific\n",
      "\t Western culture\n",
      "\t United States\n",
      "\t traditional aspects\n",
      "\t new ethnic group distinct\n",
      "\t large-scale organized cities\n",
      "\t chiefdoms\n",
      "\t city-states\n",
      "\t caboclos\n",
      "\t geology\n",
      "\t irrigation\n",
      "\t planting\n",
      "\t medicine\n",
      "\t physics\n",
      "\t mathematics\n",
      "\t astronomy\n",
      "\t writing\n",
      "\t Mexico\n",
      "\t Bolivia\n",
      "\t Guaraní\n",
      "\t Europeans\n",
      "\t degrees\n",
      "\t scientific contexts\n",
      "\t sizable populations\n",
      "\t índios\n",
      "\t indios\n",
      "\t French\n",
      "\t mining\n",
      "\t Peru\n",
      "\t Nahuatl\n",
      "\t Ecuador\n",
      "\t Guatemala\n",
      "\t cognates\n",
      "\t social organization\n",
      "\t Aymara\n",
      "\t relative isolation\n",
      "\t preferred use\n",
      "\t kind of racial\n",
      "\t Guianas\n",
      "\t Spanish\n",
      "\t Portuguese\n",
      "\t Quebec\n",
      "\t sculpture\n",
      "\t law\n",
      "\t world\n",
      "\t pluralities\n",
      "\t testament\n",
      "\t work\n",
      "\t outright majorities\n",
      "\t kingdoms\n",
      "\t vast knowledge of engineering\n",
      "\t ethnicity\n",
      "\t indianen\n",
      "\t Dutch\n",
      "\t years\n",
      "\t Indians\n",
      "\t reshaping\n",
      "\t blend\n",
      "\t Aleuts\n",
      "\t agricultural endowment\n",
      "\t goldsmithing\n",
      "\t empires\n",
      "\t descendants\n",
      "\t speakers\n",
      "\t subset\n",
      "\t Christopher Columbus\n",
      "\t favour\n",
      "\t instance\n",
      "\t continent\n",
      "\t unifying concept\n",
      "\t modern needs\n",
      "\t hunter-gatherers\n",
      "\t Wikipedia\n",
      "\t free encyclopedia\n",
      "\t search\n",
      "\t English-speaking Caribbean\n",
      "\t impact\n",
      "\t millions\n",
      "\t politics\n",
      "\t ladinos\n",
      "\t aquaculture\n",
      "\t Application\n",
      "\t large minorities\n",
      "\t mix of farming\n",
      "\t Amazon basin\n",
      "\t societies\n",
      "\t parts\n",
      "\t Terminology\n",
      "\t islands\n",
      "\t centuries\n",
      "\n",
      "\n",
      "Wikipedia-Indigeneous-Peoples-of-the-Americas.txt.1\n",
      "\n",
      "Statistics: {'character_count': 5004, 'transaction_count': 6}\n",
      "\n",
      "Number of Key Phrases: 116\n",
      "\t native peoples'\n",
      "\t Indigenous Australians\n",
      "\t Native Americans\n",
      "\t Americas\n",
      "\t Indigenous genetic studies\n",
      "\t South America\n",
      "\t American Indians\n",
      "\t native languages\n",
      "\t primacy of indigenous peoples' tenure\n",
      "\t full-blooded Indigenous person\n",
      "\t South Siberia\n",
      "\t use of terms\n",
      "\t thousands of years\n",
      "\t broader subsets of peoples\n",
      "\t pueblos indígenas\n",
      "\t northwest North America\n",
      "\t original peoples'\n",
      "\t common term\n",
      "\t continents\n",
      "\t East Beringia\n",
      "\t derogatory terms\n",
      "\t controversy\n",
      "\t South-Asian nationality\n",
      "\t foreign-language terms\n",
      "\t pueblos nativos\n",
      "\t povos indígenas\n",
      "\t Alaska Natives\n",
      "\t people of different cultures\n",
      "\t common of formal\n",
      "\t pueblos originarios\n",
      "\t genetic evidence\n",
      "\t Brazil\n",
      "\t Laurentide Ice Sheet\n",
      "\t century\n",
      "\t land bridge of Beringia\n",
      "\t ice age\n",
      "\t Aborígene\n",
      "\t Spanish\n",
      "\t isolation\n",
      "\t United States government\n",
      "\t Indian rights movement\n",
      "\t single ancestral population\n",
      "\t Cordilleran Ice Sheets\n",
      "\t sea level rise\n",
      "\t specifics of Paleo-Indian migration\n",
      "\t shared language\n",
      "\t specific country\n",
      "\t DNA studies\n",
      "\t nomadic inhabitants\n",
      "\t single group naming convention\n",
      "\t small population\n",
      "\t Archeological evidence\n",
      "\t Illustration of Paleo-Indians\n",
      "\t sea levels\n",
      "\t broad subsets\n",
      "\t Pacific Northwest coast\n",
      "\t Amerindian-specific contexts\n",
      "\t extinct Pleistocene megafauna\n",
      "\t low snowfall\n",
      "\t certain cultural attributes\n",
      "\t ice-free corridors\n",
      "\t Africa\n",
      "\t primitive boats\n",
      "\t sounding designations\n",
      "\t earlier explorers\n",
      "\t example\n",
      "\t migrations\n",
      "\t historical relationship\n",
      "\t region\n",
      "\t Argentina\n",
      "\t índio\n",
      "\t glacial refugium\n",
      "\t herds\n",
      "\t Early settlers\n",
      "\t meters\n",
      "\t endonyms\n",
      "\t noun\n",
      "\t periods of conflict\n",
      "\t colonizers\n",
      "\t countries\n",
      "\t Main article\n",
      "\t separation of populations\n",
      "\t subject of ongoing research\n",
      "\t area of Altai Republic\n",
      "\t acceptable ways\n",
      "\t discussion\n",
      "\t routes\n",
      "\t indios filipinos\n",
      "\t theories\n",
      "\t world\n",
      "\t foot\n",
      "\t Europe\n",
      "\t exact dates\n",
      "\t indiano\n",
      "\t Portuguese equivalents\n",
      "\t hunter-gatherer\n",
      "\t settlement\n",
      "\t Chile\n",
      "\t ethnonym\n",
      "\t human habitation\n",
      "\t aborigine\n",
      "\t colonists' attempts\n",
      "\t information\n",
      "\t dispute\n",
      "\t glyptodont\n",
      "\t names\n",
      "\t enemies\n",
      "\t tribes\n",
      "\t Wisconsin glaciation\n",
      "\t time range\n",
      "\t glaciers\n",
      "\t English exonyms\n",
      "\t agreements\n",
      "\t aborigen\n",
      "\t Canada\n",
      "\t half\n",
      "\n",
      "\n",
      "Wikipedia-Indigeneous-Peoples-of-the-Americas.txt.2\n",
      "\n",
      "Statistics: {'character_count': 2561, 'transaction_count': 3}\n",
      "\n",
      "Number of Key Phrases: 58\n",
      "\t Central American Native American populations\n",
      "\t Americas\n",
      "\t present North American Native American populations\n",
      "\t Native Americans\n",
      "\t radiocarbon years\n",
      "\t calendar years\n",
      "\t years old\n",
      "\t remains\n",
      "\t southern Native American branches\n",
      "\t North American indigenous peoples\n",
      "\t Clovis culture\n",
      "\t modern native population\n",
      "\t Montana\n",
      "\t autosomal DNA\n",
      "\t Anzick Clovis burial\n",
      "\t Clovis artifacts\n",
      "\t indigenous Americans\n",
      "\t intact human skeleton\n",
      "\t dated Paleo-Indians\n",
      "\t earliest human activity\n",
      "\t Stone tools\n",
      "\t South America\n",
      "\t East Asians\n",
      "\t glacial period\n",
      "\t single founding population\n",
      "\t East Asian origins\n",
      "\t Late Glacial Maximum\n",
      "\t crafted lithic flaked tools\n",
      "\t different geographical areas of Mexico\n",
      "\t sistema Sac Actun\n",
      "\t Mexico's eastern Yucatán Peninsula\n",
      "\t differences\n",
      "\t primary evidence\n",
      "\t early divergence\n",
      "\t scrapers\n",
      "\t cultural periods\n",
      "\t assimilated previous migrants\n",
      "\t underwater caves\n",
      "\t projectile points\n",
      "\t water nymph\n",
      "\t Naia\n",
      "\t invasions subsequent\n",
      "\t lineage\n",
      "\t close association\n",
      "\t RCBP\n",
      "\t Greek mythology\n",
      "\t anthropologists\n",
      "\t River site\n",
      "\t teenage girl\n",
      "\t infants\n",
      "\t individual\n",
      "\t year-old infant\n",
      "\t widespread habitation\n",
      "\t Archaeologists\n",
      "\t hypotheses\n",
      "\t study\n",
      "\t data\n",
      "\t implication\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load in text files and do key phrase extraction on each file\n",
    "key_phrase_analysis = client.extract_key_phrases(documents=texts, show_stats=True)\n",
    "\n",
    "#For each text file, get and print key phrases and document statistics\n",
    "for doc in key_phrase_analysis:\n",
    "    if not doc.is_error:\n",
    "        # Print the document title\n",
    "        print(doc['id'])\n",
    "        # Print stats for each file\n",
    "        stats = doc.statistics\n",
    "        print('\\nStatistics: {}'.format(stats))\n",
    "        \n",
    "        # Get the key phrases in this review\n",
    "        key_phrases = doc.key_phrases\n",
    "        print('\\nNumber of Key Phrases: {}'.format(len(key_phrases)))\n",
    "        # Print each key phrases on a new line\n",
    "        for key_phrase in key_phrases:\n",
    "            print('\\t', key_phrase)\n",
    "        print('\\n')\n",
    "\n",
    "    if doc.is_error:\n",
    "        print(doc.id, doc.error)"
   ]
  },
  {
   "source": [
    "## Extract Known Entities\n",
    "\n",
    "Next, let's look for common entities in our text responses. *Entities* are things that reference some commonly understood type of item. \n",
    "For example, a location, a person, or an organization. The following code block pulls out \"Organization\", \"Person\", \"Location, and \"Other\" entities. \n",
    "\n",
    "A full list of supported entities can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/named-entity-types?tabs=general).\n",
    "\n",
    "### More Info\n",
    "Some entities are sufficiently well-known to have an associated Wikipedia page. The Text Analytics service can also return the URL for that page using the \"recognize_linked_entities\" method. For more information, [check out the Python SDK method documentation here](https://docs.microsoft.com/en-us/python/api/azure-ai-textanalytics/azure.ai.textanalytics.textanalyticsclient?view=azure-python#recognize-entities-documents----kwargs-)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.0\n",
      " - Person: Henry Eeles Dresser (Confidence: 0.91)\n",
      " - Person: Richard Bowdler Sharpe (Confidence: 0.88)\n",
      " - Location: Europe (Confidence: 0.58)\n",
      " - Person: Ray (Confidence: 0.57)\n",
      " - Person: Francis Willughby (Confidence: 0.79)\n",
      " - Person: John Gould (Confidence: 0.88)\n",
      " - Location: Europe (Confidence: 0.4)\n",
      " - Person: Sharpe (Confidence: 0.79)\n",
      " - Organization: Zoological Society of London (Confidence: 0.76)\n",
      " - Person: Gould (Confidence: 0.79)\n",
      " - Location: Europe (Confidence: 0.71)\n",
      " - Location: North Africa (Confidence: 0.73)\n",
      " - Location: Middle East (Confidence: 0.42)\n",
      " - Location: Atlantic archipelagos (Confidence: 0.49)\n",
      " - Location: Madeira (Confidence: 0.4)\n",
      " - Location: Canary Islands (Confidence: 0.46)\n",
      " - Location: Azores (Confidence: 0.5)\n",
      " - Person: Dresser (Confidence: 0.38)\n",
      " - Person: Dresser (Confidence: 0.3)\n",
      " - Person: Gerrard Keulemans (Confidence: 0.49)\n",
      " - Person: Sharpe (Confidence: 0.61)\n",
      " - Location: Europe (Confidence: 0.45)\n",
      " - Person: Dresser (Confidence: 0.78)\n",
      " - Location: Europe (Confidence: 0.28)\n",
      " - Person: Erwin Stresemann (Confidence: 0.7)\n",
      " - Person: Conrad Gessner (Confidence: 0.75)\n",
      " - Person: Ulisse Aldrovandi (Confidence: 0.64)\n",
      " - Person: Pierre Belon (Confidence: 0.8)\n",
      " - Person: Aristotle (Confidence: 0.56)\n",
      " - Person: Francis Bacon (Confidence: 0.71)\n",
      " - Person: John Ray (Confidence: 0.82)\n",
      " - Person: John Wilkins (Confidence: 0.69)\n",
      " - Person: Francis Willughby (Confidence: 0.79)\n",
      " - Person: Ray (Confidence: 0.51)\n",
      " - Person: Willughby (Confidence: 0.28)\n",
      " - Person: Georges Cuvier (Confidence: 0.56)\n",
      " - Person: Carl Linnaeus (Confidence: 0.66)\n",
      "\n",
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.1\n",
      " - Person: John Gould (Confidence: 0.85)\n",
      " - Location: Europe (Confidence: 0.34)\n",
      " - Person: Richard Bowdler Sharpe (Confidence: 0.85)\n",
      " - Organization: Zoological Society of London (Confidence: 0.77)\n",
      " - Person: Gould (Confidence: 0.8)\n",
      " - Person: Gould (Confidence: 0.64)\n",
      " - Location: Europe (Confidence: 0.65)\n",
      " - Location: North Africa (Confidence: 0.64)\n",
      " - Location: Middle East (Confidence: 0.38)\n",
      " - Location: Atlantic (Confidence: 0.42)\n",
      " - Location: Madeira (Confidence: 0.41)\n",
      " - Location: Canary Islands (Confidence: 0.44)\n",
      " - Location: Azores (Confidence: 0.39)\n",
      " - Person: Henry Eeles Dresser (Confidence: 0.91)\n",
      " - Person: Dresser (Confidence: 0.43)\n",
      "\n",
      "Wikipedia-Hypatia.txt.0\n",
      " - Location: Alexandria (Confidence: 0.24)\n",
      " - Location: Egypt (Confidence: 0.3)\n",
      " - Location: Alexandria (Confidence: 0.48)\n",
      " - Location: Egypt (Confidence: 0.54)\n",
      " - Location: Alexandria (Confidence: 0.76)\n",
      " - Location: Egypt (Confidence: 0.45)\n",
      " - Location: Neoplatonic school (Confidence: 0.54)\n",
      " - Location: Alexandria (Confidence: 0.51)\n",
      " - Person: Hypatia (Confidence: 0.3)\n",
      " - Person: Diophantus (Confidence: 0.34)\n",
      " - Person: Diophantus (Confidence: 0.39)\n",
      " - Person: Hypatia (Confidence: 0.37)\n",
      " - Person: Ptolemy (Confidence: 0.56)\n",
      " - Person: Theon (Confidence: 0.6)\n",
      " - Person: Synesius (Confidence: 0.46)\n",
      " - Location: Alexandria (Confidence: 0.47)\n",
      " - Person: Hypatia (Confidence: 0.53)\n",
      " - Person: Orestes (Confidence: 0.57)\n",
      " - Location: Alexandria (Confidence: 0.22)\n",
      " - Person: Cyril (Confidence: 0.65)\n",
      " - Location: Alexandria (Confidence: 0.31)\n",
      " - Person: Cyril (Confidence: 0.49)\n",
      " - Person: Peter.[8][9]\n",
      "\n",
      "Hypatia (Confidence: 0.51)\n",
      " - Person: Damascius (Confidence: 0.43)\n",
      " - Person: Hypatia (Confidence: 0.41)\n",
      " - Person: Catherine (Confidence: 0.59)\n",
      " - Location: Alexandria (Confidence: 0.3)\n",
      " - Person: Charles Kingsley (Confidence: 0.89)\n",
      " - Person: Hypatia (Confidence: 0.27)\n",
      " - Person: Hypatia (Confidence: 0.37)\n",
      " - Location: Library of Alexandria (Confidence: 0.56)\n",
      " - Person: Hypatia (Confidence: 0.37)\n",
      " - Person: Theon (Confidence: 0.59)\n",
      " - Location: Alexandria (Confidence: 0.38)\n",
      " - Person: Hypatia (Confidence: 0.18)\n",
      " - Person: Theon (Confidence: 0.45)\n",
      " - Location: Alexandria (Confidence: 0.29)\n",
      " - Person: Edward J. Watts (Confidence: 0.83)\n",
      "\n",
      "Wikipedia-Hypatia.txt.1\n",
      " - Person: Hypatia (Confidence: 0.35)\n",
      " - Person: Theon (Confidence: 0.65)\n",
      " - Person: Epiphanius (Confidence: 0.4)\n",
      " - Person: Hypatia (Confidence: 0.37)\n",
      " - Person: Richard Hoche (Confidence: 0.75)\n",
      " - Person: Hypatia (Confidence: 0.38)\n",
      " - Person: Damascius (Confidence: 0.51)\n",
      " - Person: Arcadius (Confidence: 0.48)\n",
      " - Person: John Malalas (Confidence: 0.7)\n",
      " - Person: Robert Penella (Confidence: 0.64)\n",
      " - Person: Iamblichus (Confidence: 0.29)\n",
      " - Person: Plotinus.[18 (Confidence: 0.66)\n",
      " - Person: Alexandria (Confidence: 0.37)\n",
      " - Location: Athens (Confidence: 0.37)\n",
      " - Location: Alexandria (Confidence: 0.43)\n",
      " - Location: Alexandria (Confidence: 0.4)\n",
      " - Person: Theon (Confidence: 0.59)\n",
      " - Person: Hypatia (Confidence: 0.3)\n",
      " - Location: Libya (Confidence: 0.41)\n",
      " - Person: Synesius (Confidence: 0.63)\n",
      " - Person: Hypatia (Confidence: 0.45)\n",
      " - Person: Herculianus (Confidence: 0.6)\n",
      " - Person: Synesius (Confidence: 0.62)\n",
      " - Person: Hypatia (Confidence: 0.48)\n",
      " - Person: Hypatia (Confidence: 0.35)\n",
      " - Person: Socrates (Confidence: 0.39)\n",
      " - Location: Constantinople (Confidence: 0.24)\n",
      " - Person: Hypatia (Confidence: 0.32)\n",
      " - Location: Alexandria (Confidence: 0.34)\n",
      " - Person: Hypatia (Confidence: 0.39)\n",
      " - Person: Theon (Confidence: 0.5)\n",
      " - Person: Plato (Confidence: 0.39)\n",
      "\n",
      "Wikipedia-Hypatia.txt.2\n",
      " - Person: Philostorgius (Confidence: 0.21)\n",
      " - Person: Hypatia (Confidence: 0.32)\n",
      " - Person: Hesychius (Confidence: 0.36)\n",
      " - Person: Damascius (Confidence: 0.64)\n",
      " - Person: Hypatia (Confidence: 0.28)\n",
      " - Person: Hypatia (Confidence: 0.36)\n",
      "\n",
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.0\n",
      " - Location: Americas (Confidence: 0.46)\n",
      " - Location: South America (Confidence: 0.54)\n",
      " - Location: Americas (Confidence: 0.5)\n",
      " - Location: Amazon basin (Confidence: 0.72)\n",
      " - Location: Americas (Confidence: 0.62)\n",
      " - Location: Bolivia (Confidence: 0.81)\n",
      " - Location: Canada (Confidence: 0.8)\n",
      " - Location: Ecuador (Confidence: 0.87)\n",
      " - Location: Guatemala (Confidence: 0.83)\n",
      " - Location: Mexico (Confidence: 0.82)\n",
      " - Location: Peru (Confidence: 0.72)\n",
      " - Location: Americas (Confidence: 0.45)\n",
      " - Person: Christopher Columbus (Confidence: 0.86)\n",
      " - Location: India (Confidence: 0.63)\n",
      " - Location: East Indies (Confidence: 0.37)\n",
      " - Location: Americas (Confidence: 0.41)\n",
      " - Location: Americas (Confidence: 0.47)\n",
      " - Location: Americas (Confidence: 0.39)\n",
      " - Location: Quebec (Confidence: 0.65)\n",
      " - Location: Canada (Confidence: 0.71)\n",
      " - Organization: First Nations and Arctic Inuit (Confidence: 0.42)\n",
      " - Location: Canada (Confidence: 0.53)\n",
      " - Location: Brazil (Confidence: 0.74)\n",
      " - Location: Hispanic America (Confidence: 0.58)\n",
      "\n",
      "Wikipedia-A-History-of-the-Birds-of-Europe.txt.1\n",
      " - Location: Argentina (Confidence: 0.7)\n",
      " - Location: Chile (Confidence: 0.8)\n",
      " - Location: Brazil (Confidence: 0.75)\n",
      " - Location: Brazil (Confidence: 0.83)\n",
      " - Location: Europe (Confidence: 0.62)\n",
      " - Location: Africa (Confidence: 0.61)\n",
      " - Location: United States (Confidence: 0.74)\n",
      " - Location: Americas (Confidence: 0.39)\n",
      " - Location: Americas (Confidence: 0.43)\n",
      " - Location: Americas (Confidence: 0.56)\n",
      " - Location: United States (Confidence: 0.68)\n",
      " - Location: Americas (Confidence: 0.5)\n",
      " - Location: South America (Confidence: 0.51)\n",
      " - Location: Wisconsin (Confidence: 0.37)\n",
      " - Location: Beringia (Confidence: 0.26)\n",
      " - Location: Siberia (Confidence: 0.42)\n",
      " - Location: North America (Confidence: 0.5)\n",
      " - Location: Alaska (Confidence: 0.43)\n",
      " - Location: Alaska (Confidence: 0.42)\n",
      " - Location: North America (Confidence: 0.47)\n",
      " - Location: Alaska (Confidence: 0.57)\n",
      " - Location: Americas (Confidence: 0.44)\n",
      " - Location: Beringia (Confidence: 0.31)\n",
      " - Location: Canada (Confidence: 0.58)\n",
      " - Location: Laurentide (Confidence: 0.48)\n",
      " - Location: Pacific Northwest coast (Confidence: 0.58)\n",
      " - Location: South America (Confidence: 0.56)\n",
      " - Location: Altai Republic (Confidence: 0.83)\n",
      "\n",
      "Wikipedia-Hypatia.txt.0\n",
      " - Location: Americas (Confidence: 0.42)\n",
      " - Location: Late Glacial Maximum (Confidence: 0.36)\n",
      " - Location: Americas (Confidence: 0.34)\n",
      " - Location: Americas (Confidence: 0.38)\n",
      " - Location: Montana (Confidence: 0.65)\n",
      " - Location: Montana (Confidence: 0.58)\n",
      " - Location: South America (Confidence: 0.51)\n",
      " - Location: Montana (Confidence: 0.61)\n",
      " - Location: underwater caves (Confidence: 0.65)\n",
      " - Location: Mexico (Confidence: 0.8)\n",
      " - Location: Yucatán Peninsula (Confidence: 0.46)\n",
      " - Location: Upward Sun River (Confidence: 0.68)\n",
      " - Location: East Asians (Confidence: 0.45)\n",
      " - Location: Mexico (Confidence: 0.73)\n"
     ]
    }
   ],
   "source": [
    "# Use the client and reviews you created previously to get named entities\n",
    "# Set batch size to be 5 (max input for recognize_entities)\n",
    "batch_size = 5\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    # Create subset of dictionaries\n",
    "    batch = texts[i:i+batch_size] \n",
    "    #Run entity analysis on sets of 5 or fewer inputs \n",
    "    entity_analysis = client.recognize_entities(batch)\n",
    "    \n",
    "    # Create a list of the entity analysis results\n",
    "    docs = [doc for doc in entity_analysis if not doc.is_error]\n",
    "\n",
    "    # Iterate through texts and print entity analysis results\n",
    "    for idx, doc in enumerate(docs):\n",
    "        # Print text ID \n",
    "        print(\"\\n\" + texts[idx]['id'])\n",
    "        for entity in doc.entities:\n",
    "            # Only get Organization and Other entitites\n",
    "            # TO DO: Add or remove entities to this list according to needs/interests\n",
    "            if entity.category in ['Organization','Person', 'Location', 'Other']:\n",
    "                print(' - {}: {} (Confidence: {})'.format(entity.category, entity.text, entity.confidence_score))"
   ]
  },
  {
   "source": [
    "## Going Further\n",
    "\n",
    "Congratulations! You did machine learning on text to get some (hopefully) helpful insights!  \n",
    "\n",
    "There are other services available to you, including sentiment analysis and language detection. For more information on those services, check out the Microsoft Docs [Python Cognitive Services Text Analytics SDK](https://docs.microsoft.com/en-us/python/api/azure-ai-textanalytics/azure.ai.textanalytics.textanalyticsclient?view=azure-python). Fun fact: you can also do [sentiment analysis in Excel](https://www.mrexcel.com/excel-tips/sentiment-analysis/)!\n",
    "\n",
    "You can also use Azure Cognitive Services for all sorts of other things like Computer Vision, Anomaly Detection, and Speech Recognition! [Here's a handy overview](https://docs.microsoft.com/en-us/python/api/overview/azure/cognitive-services?view=azure-python) that covers what else you can do in Python.\n",
    "\n",
    "Questions? Requests? Let us know! Open a Pull Request on our repo or send us an e-mail: AskAMaker@microsoft.com\n",
    "\n",
    "Thanks for reading!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}